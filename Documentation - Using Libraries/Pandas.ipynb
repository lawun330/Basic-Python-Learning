{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277ae8a4",
   "metadata": {},
   "source": [
    "# Documentation - Using Libraries: Pandas\n",
    "This educational notebook illustrates the use of the `pandas` library, a powerful data manipulation and analysis tool in Python.\n",
    "\n",
    "It covers:\n",
    "- Series: One-dimensional labeled arrays\n",
    "- DataFrames: Two-dimensional labeled data structures\n",
    "- Data Operations:\n",
    "  - Creation and manipulation of Series/DataFrames\n",
    "  - Indexing and selection\n",
    "  - Handling missing data\n",
    "  - Grouping and aggregation\n",
    "  - Merging and joining datasets\n",
    "  - Pivot tables\n",
    "- File Operations:\n",
    "  - Reading/writing CSV files\n",
    "  - Reading/writing Excel files\n",
    "  - Reading HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31be680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy # uncomment this line to install\n",
    "# %pip install pandas # uncomment this line to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbb5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b4282",
   "metadata": {},
   "source": [
    "## Series\n",
    "### A. Creating a Series\n",
    "We can make a series from \n",
    "- a list\n",
    "- a numpy array\n",
    "- a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823b4fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    m\n",
      "1    h\n",
      "2    n\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# SERIES FROM LIST\n",
    "my_list = ['m', 'h', 'n']\n",
    "print(pd.Series(data=my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1658161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    4\n",
      "2    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SERIES FROM NUMPY ARRAY\n",
    "my_np_array = np.array([2, 4, 6])\n",
    "print(pd.Series(my_np_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48c5146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key1    lowercase string\n",
      "key2    UPPERCASE STRING\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# SERIES FROM DICTIONARY\n",
    "## dictionary's keys become indexes / labels\n",
    "my_dict = {'key1':'lowercase string', 'key2':'UPPERCASE STRING'}\n",
    "print(pd.Series(my_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38caa2b2",
   "metadata": {},
   "source": [
    "### B. Labelling a Series\n",
    "We can give a custom label for each key of a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9649aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label1    m\n",
      "label2    h\n",
      "label3    n\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ASSIGNING INDEXES / LABELS\n",
    "labels =['label1', 'label2', 'label3']\n",
    "print(pd.Series(data=my_list, index=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2344a",
   "metadata": {},
   "source": [
    "### C. Indexing a Series\n",
    "We can access elements of a list using indices. Similarly, we can get associated values of a row in a series with an index (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7de9f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row value: m\n"
     ]
    }
   ],
   "source": [
    "# INDEXING SERIES\n",
    "print(\"row value:\", pd.Series(data=my_list, index=labels)['label1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0fcd3",
   "metadata": {},
   "source": [
    "### D. Adding two Series\n",
    "If we add two series, values under the same label are added. Otherwise, they are filled with <code>Nan</code>. The number of columns increases as unique-labelled columns are added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09bdda11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA       1\n",
      "UK        2\n",
      "Russia    3\n",
      "NK        4\n",
      "dtype: int64\n",
      "\n",
      "USA        4\n",
      "Myanmar    0\n",
      "Russia     2\n",
      "SK         1\n",
      "dtype: int64\n",
      "\n",
      "Myanmar    NaN\n",
      "NK         NaN\n",
      "Russia     5.0\n",
      "SK         NaN\n",
      "UK         NaN\n",
      "USA        5.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SERIES ADDITION\n",
    "se1 = pd.Series([1, 2, 3, 4], index=['USA', 'UK', 'Russia', 'NK'])\n",
    "se2 = pd.Series([4, 0, 2, 1], index=['USA', 'Myanmar', 'Russia', 'SK'])\n",
    "print(se1)\n",
    "print()\n",
    "print(se2)\n",
    "print()\n",
    "print(se1 + se2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c60d86",
   "metadata": {},
   "source": [
    "## METHOD seed()\n",
    "A seed is some number that whenever it is used with the method <code>seed()</code>, the output is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9270f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c6e4b1",
   "metadata": {},
   "source": [
    "\n",
    "## Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03090b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col1      col2      col3      col4      col5\n",
      "row1  2.706850  0.628133  0.907969  0.503826  0.651118\n",
      "row2 -0.319318 -0.848077  0.605965 -2.018168  0.740122\n",
      "row3  0.528813 -0.589001  0.188695 -0.758872 -0.933237\n",
      "row4  0.955057  0.190794  1.978757  2.605967  0.683509\n"
     ]
    }
   ],
   "source": [
    "# DATAFRAME\n",
    "df = pd.DataFrame(np.random.randn(4, 5), index='row1 row2 row3 row4'.split(), columns=['col1', 'col2', 'col3', 'col4', 'col5'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c159cf1",
   "metadata": {},
   "source": [
    "### A. Type Checking\n",
    "The type of a dataframe differs from the type of its column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7acbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df)) # frame.DataFrame object\n",
    "print(type(df['col3'])) # series.Series object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11286f8d",
   "metadata": {},
   "source": [
    "### B. Summing vs. Adding columns\n",
    "We can sum all values of the columns in a dataframe with the <code>+</code> operator. We can also add/insert one or more new columns to a dataframe with its column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c1fa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col1      col2      col3      col4      col5     total\n",
      "row1  2.706850  0.628133  0.907969  0.503826  0.651118  5.397896\n",
      "row2 -0.319318 -0.848077  0.605965 -2.018168  0.740122 -1.839476\n",
      "row3  0.528813 -0.589001  0.188695 -0.758872 -0.933237 -1.563601\n",
      "row4  0.955057  0.190794  1.978757  2.605967  0.683509  6.414084\n",
      "\n",
      "          col1      col2      col3      col4      col5     total countries\n",
      "row1  2.706850  0.628133  0.907969  0.503826  0.651118  5.397896        US\n",
      "row2 -0.319318 -0.848077  0.605965 -2.018168  0.740122 -1.839476        UK\n",
      "row3  0.528813 -0.589001  0.188695 -0.758872 -0.933237 -1.563601   Ukarine\n",
      "row4  0.955057  0.190794  1.978757  2.605967  0.683509  6.414084    Uganda\n"
     ]
    }
   ],
   "source": [
    "# COLUMNS ADDITION\n",
    "df['total'] = df['col1'] + df['col2'] + df['col3'] + df['col4'] + df['col5']\n",
    "print(df)\n",
    "\n",
    "print()\n",
    "\n",
    "# ADDING COLUMN\n",
    "df['countries'] = ['US', 'UK', 'Ukarine', 'Uganda'] # insert a new column\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7357e",
   "metadata": {},
   "source": [
    "### C. Getting Labels of rows and columns\n",
    "A label of a row is called an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aaed817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row1', 'row2', 'row3', 'row4'], dtype='object')\n",
      "\n",
      "Index(['col1', 'col2', 'col3', 'col4', 'col5', 'total', 'countries'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# GETTING LABELS OF ROWS\n",
    "print(df.index)\n",
    "\n",
    "print()\n",
    "\n",
    "# GETTING LABELS OF COLUMNS\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a046659",
   "metadata": {},
   "source": [
    "### D. Accessing rows and columns\n",
    "We can only pass a single argument to access rows or columns. If we need to access multiple rows or columns, we use double brackets.\n",
    "\n",
    "We can use two methods to retrieve a row.\n",
    "1. <code>iloc()</code> -> pass an index, a position\n",
    "2. <code>loc()</code> -> pass a label, a name\n",
    "\n",
    "We can also pass both a row and a column to select a specific element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4efedea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col1      col2\n",
      "row1  2.706850  0.628133\n",
      "row2 -0.319318 -0.848077\n",
      "row3  0.528813 -0.589001\n",
      "row4  0.955057  0.190794\n",
      "\n",
      "col1          2.70685\n",
      "col2         0.628133\n",
      "col3         0.907969\n",
      "col4         0.503826\n",
      "col5         0.651118\n",
      "total        5.397896\n",
      "countries          US\n",
      "Name: row1, dtype: object\n",
      "\n",
      "col1          2.70685\n",
      "col2         0.628133\n",
      "col3         0.907969\n",
      "col4         0.503826\n",
      "col5         0.651118\n",
      "total        5.397896\n",
      "countries          US\n",
      "Name: row1, dtype: object\n",
      "\n",
      "row2 col3 element: 0.6059653494949336\n"
     ]
    }
   ],
   "source": [
    "# SELECTING / INDEXING COLUMNS\n",
    "print(df[['col1', 'col2']])\n",
    "print()\n",
    "\n",
    "# SELECTING / INDEXING A ROW\n",
    "print(df.iloc[0]) # using iloc()\n",
    "print()\n",
    "print(df.loc['row1']) # using loc()\n",
    "print()\n",
    "\n",
    "# SELECTING / INDEXING AN ELEMENT\n",
    "print('row2 col3 element:', df.loc['row2']['col3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a590f",
   "metadata": {},
   "source": [
    "### E(a). Modifying Labels of rows: One Layer\n",
    "\n",
    "We can \n",
    "- set values under a column as labels for row using the <code>set_index()</code> method.\n",
    "- reset index with the <code>reset_index()</code> method.\n",
    "- change the header of index column (key column) by setting the <code>index.names</code> attribute. Alternatively, we can change the name of the column before it becomes the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e1a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               col1      col2      col3      col4      col5     total\n",
      "countries                                                            \n",
      "US         2.706850  0.628133  0.907969  0.503826  0.651118  5.397896\n",
      "UK        -0.319318 -0.848077  0.605965 -2.018168  0.740122 -1.839476\n",
      "Ukarine    0.528813 -0.589001  0.188695 -0.758872 -0.933237 -1.563601\n",
      "Uganda     0.955057  0.190794  1.978757  2.605967  0.683509  6.414084\n",
      "\n",
      "  countries      col1      col2      col3      col4      col5     total\n",
      "0        US  2.706850  0.628133  0.907969  0.503826  0.651118  5.397896\n",
      "1        UK -0.319318 -0.848077  0.605965 -2.018168  0.740122 -1.839476\n",
      "2   Ukarine  0.528813 -0.589001  0.188695 -0.758872 -0.933237 -1.563601\n",
      "3    Uganda  0.955057  0.190794  1.978757  2.605967  0.683509  6.414084\n",
      "\n",
      "                      col1      col2      col3      col4      col5     total\n",
      "countries_with_U                                                            \n",
      "US                2.706850  0.628133  0.907969  0.503826  0.651118  5.397896\n",
      "UK               -0.319318 -0.848077  0.605965 -2.018168  0.740122 -1.839476\n",
      "Ukarine           0.528813 -0.589001  0.188695 -0.758872 -0.933237 -1.563601\n",
      "Uganda            0.955057  0.190794  1.978757  2.605967  0.683509  6.414084\n"
     ]
    }
   ],
   "source": [
    "# ASSIGNING INDEXES / LABELS\n",
    "df.set_index('countries', inplace=True) # set a column as index/label for rows\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# RESETTING INDEX\n",
    "print(df.reset_index())\n",
    "print()\n",
    "\n",
    "# ASSIGN / CHANGE INDEX HEADER\n",
    "df.index.names = ['countries_with_U']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062790a",
   "metadata": {},
   "source": [
    "### E(b). Modifying Labels of rows: Multiple Layers\n",
    "\n",
    "First, we create each layer of indexes. Then, layers of indexes are zipped together using the <code>zip()</code> method. It is then transformed into the multi-index object using the <code>MultiIndex.from_tuples()</code> method. Finally, we use the <code>set_index()</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4665c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('main_indexA', 'sub_index1'), ('main_indexA', 'sub_index2'), ('main_indexB', 'sub_index1'), ('main_indexB', 'sub_index2')]\n",
      "\n",
      "MultiIndex([('main_indexA', 'sub_index1'),\n",
      "            ('main_indexA', 'sub_index2'),\n",
      "            ('main_indexB', 'sub_index1'),\n",
      "            ('main_indexB', 'sub_index2')],\n",
      "           )\n",
      "\n",
      "                            col1      col2      col3      col4      col5  \\\n",
      "main_indexA sub_index1  2.706850  0.628133  0.907969  0.503826  0.651118   \n",
      "            sub_index2 -0.319318 -0.848077  0.605965 -2.018168  0.740122   \n",
      "main_indexB sub_index1  0.528813 -0.589001  0.188695 -0.758872 -0.933237   \n",
      "            sub_index2  0.955057  0.190794  1.978757  2.605967  0.683509   \n",
      "\n",
      "                           total  \n",
      "main_indexA sub_index1  5.397896  \n",
      "            sub_index2 -1.839476  \n",
      "main_indexB sub_index1 -1.563601  \n",
      "            sub_index2  6.414084  \n"
     ]
    }
   ],
   "source": [
    "# ASSIGNING INDEXES / LABELS WITH HIERACHY\n",
    "\n",
    "## create lists of elements which are to be labels\n",
    "outside = 'main_indexA main_indexA main_indexB main_indexB'.split()\n",
    "inside = 'sub_index1 sub_index2 sub_index1 sub_index2'.split()\n",
    "\n",
    "## put two items from each list, in a tuple\n",
    "hier_index = list(zip(outside, inside))\n",
    "print(hier_index)\n",
    "print()\n",
    "\n",
    "## transform it to multi-index object\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)\n",
    "print(hier_index)\n",
    "print()\n",
    "\n",
    "## set multi-level index/label\n",
    "df.set_index(hier_index, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434155d",
   "metadata": {},
   "source": [
    "### F(a). Accessing multi-index rows with the <code>loc()</code> method\n",
    "We can access rows of a dataframe with multi-index, just as we do with a single index layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61918306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1     2.706850\n",
      "col2     0.628133\n",
      "col3     0.907969\n",
      "col4     0.503826\n",
      "col5     0.651118\n",
      "total    5.397896\n",
      "Name: sub_index1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SELECTING / INDEXING A ROW WITH MULTI-INDEX\n",
    "print(df.loc['main_indexA'].loc['sub_index1']) # values of 'main_indexA/sub_index1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d4d68",
   "metadata": {},
   "source": [
    "### F(b). Accessing multi-index rows with the <code>xs()</code> method\n",
    "We pass a single label to the <code>xs()</code> method to pack a tuple for multiple labels.\n",
    "\n",
    "The index hierachy is represented by the index level.\n",
    "- level = 0 -> search at the foremost (main) index level\n",
    "- level = n -> search at the index level 'n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7339796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1     2.706850\n",
      "col2     0.628133\n",
      "col3     0.907969\n",
      "col4     0.503826\n",
      "col5     0.651118\n",
      "total    5.397896\n",
      "Name: (main_indexA, sub_index1), dtype: float64\n",
      "                col1      col2      col3      col4      col5     total\n",
      "sub_index1  2.706850  0.628133  0.907969  0.503826  0.651118  5.397896\n",
      "sub_index2 -0.319318 -0.848077  0.605965 -2.018168  0.740122 -1.839476\n",
      "                 col1      col2      col3      col4      col5     total\n",
      "main_indexA  2.706850  0.628133  0.907969  0.503826  0.651118  5.397896\n",
      "main_indexB  0.528813 -0.589001  0.188695 -0.758872 -0.933237 -1.563601\n"
     ]
    }
   ],
   "source": [
    "print(df.xs(('main_indexA', 'sub_index1'))) # alternative approach to retrieve values of 'main_indexA/sub_index1'\n",
    "print(df.xs('main_indexA', level=0)) # values of all sub-indexes with 'main_indexA' -> 'main_indexA/sub_index1' and 'main_indexA/sub_index2'\n",
    "print(df.xs('sub_index1', level=1))  # values of all main-indexes with 'sub-index1' -> 'main_indexA/sub_index1' and 'main_indexB/sub_index1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efff5ec",
   "metadata": {},
   "source": [
    "### G. Using the <code>inplace</code> parameter\n",
    "The <code>inplace</code> parameter helps us determine whether we want changes applied to the original dataframe or the copied dataframe.\n",
    "- inplace=True -> modify the original df -> original dataframe gets modified permanently\n",
    "- inplace=False -> modify the copied df -> original dataframe does not get modified permanently\n",
    "\n",
    "By default, it is `inplace=False`.\n",
    "\n",
    "### H. Dropping / Deleting\n",
    "There are two approaches:\n",
    "1. `drop()` method -> A pandas method specifically designed for DataFrames\n",
    "    - more flexible and feature-rich\n",
    "    - can drop multiple items at once\n",
    "    - can drop rows or columns using the `axis` parameter\n",
    "        - axis=0 -> drop rows (default)\n",
    "        - axis=1 -> drop columns\n",
    "    - supports the `inplace` parameter\n",
    "    - returns a new DataFrame by default (unless inplace=True)\n",
    "2. `del` keyword -> A Python keyword, not specific to pandas\n",
    "    - simpler syntax for dropping columns\n",
    "    - can only remove one column at a time\n",
    "    - cannot be used to drop rows\n",
    "    - always modifies the original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a4b5627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            col1      col2      col3      col4      col5  \\\n",
      "main_indexB sub_index1  0.528813 -0.589001  0.188695 -0.758872 -0.933237   \n",
      "            sub_index2  0.955057  0.190794  1.978757  2.605967  0.683509   \n",
      "\n",
      "                           total  \n",
      "main_indexB sub_index1 -1.563601  \n",
      "            sub_index2  6.414084  \n",
      "\n",
      "original df with inplace = false\n",
      "                            col1      col2      col3      col4      col5  \\\n",
      "main_indexA sub_index1  2.706850  0.628133  0.907969  0.503826  0.651118   \n",
      "            sub_index2 -0.319318 -0.848077  0.605965 -2.018168  0.740122   \n",
      "main_indexB sub_index1  0.528813 -0.589001  0.188695 -0.758872 -0.933237   \n",
      "            sub_index2  0.955057  0.190794  1.978757  2.605967  0.683509   \n",
      "\n",
      "                           total  \n",
      "main_indexA sub_index1  5.397896  \n",
      "            sub_index2 -1.839476  \n",
      "main_indexB sub_index1 -1.563601  \n",
      "            sub_index2  6.414084  \n",
      "\n",
      "original df with inplace = true\n",
      "                            col1      col3      col4      col5     total\n",
      "main_indexA sub_index1  2.706850  0.907969  0.503826  0.651118  5.397896\n",
      "            sub_index2 -0.319318  0.605965 -2.018168  0.740122 -1.839476\n",
      "main_indexB sub_index1  0.528813  0.188695 -0.758872 -0.933237 -1.563601\n",
      "            sub_index2  0.955057  1.978757  2.605967  0.683509  6.414084\n",
      "                            col1      col3      col4     total\n",
      "main_indexA sub_index1  2.706850  0.907969  0.503826  5.397896\n",
      "            sub_index2 -0.319318  0.605965 -2.018168 -1.839476\n",
      "main_indexB sub_index1  0.528813  0.188695 -0.758872 -1.563601\n",
      "            sub_index2  0.955057  1.978757  2.605967  6.414084\n"
     ]
    }
   ],
   "source": [
    "# DROPPING WITH INPLACE PARAMETER\n",
    "\n",
    "print(df.drop('main_indexA', axis=0)) # try dropping a row\n",
    "print(\"\\noriginal df with inplace = false\")\n",
    "print(df) # row is not dropped because the original df is unaffected due to inplace=false\n",
    "\n",
    "df.drop('col2', axis=1, inplace=True) # try dropping a column\n",
    "print(\"\\noriginal df with inplace = true\")\n",
    "print(df) # column is dropped because  the original df is affected due to inplace=true\n",
    "\n",
    "# using del to drop a column\n",
    "del df['col5']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93349063",
   "metadata": {},
   "source": [
    "### I. Conditionals\n",
    "We can use conditionals with specific columns or rows of a dataframe or the whole dataframe itself. The result is Boolean values which can be used as a new condition to obtain filtered values of the dataframe. We can form complex conditionals from the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4325d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         col1  col3   col4  total\n",
      "main_indexA sub_index1   True  True   True   True\n",
      "            sub_index2  False  True  False  False\n",
      "main_indexB sub_index1   True  True  False  False\n",
      "            sub_index2   True  True   True   True\n",
      "\n",
      "                            col1      col3      col4     total\n",
      "main_indexA sub_index1  2.706850  0.907969  0.503826  5.397896\n",
      "            sub_index2       NaN  0.605965       NaN       NaN\n",
      "main_indexB sub_index1  0.528813  0.188695       NaN       NaN\n",
      "            sub_index2  0.955057  1.978757  2.605967  6.414084\n",
      "\n",
      "                            col1      col3      col4     total\n",
      "main_indexA sub_index1  2.706850  0.907969  0.503826  5.397896\n",
      "main_indexB sub_index2  0.955057  1.978757  2.605967  6.414084\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [col1, col3, col4, total]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# USING CONDITIONAL\n",
    "print(df > 0) # obtain booleans\n",
    "print()\n",
    "\n",
    "# FILTER THE DATAFRAME\n",
    "print(df[df > 0]) # obtain filtered values\n",
    "print()\n",
    "\n",
    "# FILTER A COLUMN\n",
    "print(df[df['total'] > 0]) # obtain filtered values\n",
    "print()\n",
    "\n",
    "# MORE CONDITIONALS\n",
    "## obtain rows (satisfying respective conditions) under 'col1' column and rows under 'col3' column \n",
    "## return empty since the two conditions are not satisfied\n",
    "print(df[(df['col1'] > 1) & (df['col3'] < 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7f2f2",
   "metadata": {},
   "source": [
    "### J. Handling Missing Data\n",
    "\n",
    "When there are null values or `NaN` in a dataframe, we can either drop or replace them with some values. \n",
    "\n",
    "- The `axis` parameter distinguishes a row from a column.\n",
    "- The `value` parameter represents an arbitary value to replace `NaN`.\n",
    "- The `thresh` parameter specifies the minimum number of non-null values required for a row or column to be kept in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd5f16e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            col1      col3      col4     total\n",
      "main_indexA sub_index1  2.706850  0.907969  0.503826  5.397896\n",
      "            sub_index2       NaN  0.605965       NaN       NaN\n",
      "main_indexB sub_index1  0.528813  0.188695       NaN       NaN\n",
      "            sub_index2  0.955057  1.978757  2.605967  6.414084\n",
      "\n",
      "                         col1   col3   col4  total\n",
      "main_indexA sub_index1  False  False  False  False\n",
      "            sub_index2   True  False   True   True\n",
      "main_indexB sub_index1  False  False   True   True\n",
      "            sub_index2  False  False  False  False\n",
      "\n",
      "                            col1      col3      col4     total\n",
      "main_indexA sub_index1   2.70685  0.907969  0.503826  5.397896\n",
      "            sub_index2     empty  0.605965     empty     empty\n",
      "main_indexB sub_index1  0.528813  0.188695     empty     empty\n",
      "            sub_index2  0.955057  1.978757  2.605967  6.414084\n",
      "\n",
      "                            col3\n",
      "main_indexA sub_index1  0.907969\n",
      "            sub_index2  0.605965\n",
      "main_indexB sub_index1  0.188695\n",
      "            sub_index2  1.978757\n",
      "\n",
      "                            col1      col3      col4     total\n",
      "main_indexA sub_index1  2.706850  0.907969  0.503826  5.397896\n",
      "main_indexB sub_index2  0.955057  1.978757  2.605967  6.414084\n"
     ]
    }
   ],
   "source": [
    "# filter the dataframe\n",
    "df = df[df > 0]\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# check null values\n",
    "print(df.isnull()) \n",
    "print()\n",
    "\n",
    "# replace columns having 'NaN' with an arbitary value\n",
    "print(df.fillna(axis=1, value='empty'))\n",
    "print()\n",
    "\n",
    "# drop columns having 'NaN'\n",
    "print(df.dropna(axis=1))\n",
    "print()\n",
    "\n",
    "# drop all rows having 'NaN' except rows having at least 4 non-null values\n",
    "print(df.dropna(axis=0, thresh=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9be04f",
   "metadata": {},
   "source": [
    "### K(a). Common Built-in Methods for Data Analysis\n",
    "\n",
    "- `head(n)` method -> Returns the first *n* rows of the DataFrame. Useful for quickly previewing data.\n",
    "- `unique()` method -> Returns an array of unique values in a Series/column, removing all duplicates.\n",
    "- `nunique()` method -> Returns the count of unique values in a Series/column.\n",
    "- `value_counts()` method -> Returns a Series containing the counts of unique values, sorted in descending order by default.\n",
    "- `sum()` method -> Calculates the sum of all values in a numeric Series/column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69d4f0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2 col3\n",
      "0     1   444  abc\n",
      "1     2   555  def\n",
      "2     3   666  ghi\n",
      "\n",
      "[444 555 666 777]\n",
      "\n",
      "4\n",
      "\n",
      "col2\n",
      "444    1\n",
      "555    1\n",
      "666    1\n",
      "777    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2442\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'col1':[1, 2, 3, 4],\n",
    "                   'col2':[444, 555, 666, 777],\n",
    "                   'col3':['abc', 'def', 'ghi', 'xyz']})\n",
    "\n",
    "print(df.head(3)) # get the first '3' rows\n",
    "print()\n",
    "print(df['col2'].unique())  # get the unique elements under a column\n",
    "print()\n",
    "print(df['col2'].nunique()) # get the number of unique elements under a column\n",
    "print()\n",
    "print(df['col2'].value_counts()) # count the unique elements under a column\n",
    "print()\n",
    "print(df['col2'].sum()) # adds everything under a column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e072b5",
   "metadata": {},
   "source": [
    "### K(b). Sorting\n",
    "We can sort values within a dataframe using the `DataFrame.sort_values()` method. \n",
    "\n",
    "The `by` parameter specifies which column(s) to sort by:\n",
    "- Single column: `by='column_name'`\n",
    "- Multiple columns: `by=['column1', 'column2']`\n",
    "\n",
    "The `ascending` parameter controls the sort order:\n",
    "- `True` -> ascending order (default)\n",
    "- `False` -> descending order\n",
    "\n",
    "For multiple columns, we can specify order per column with `ascending=[True, False]`\n",
    "\n",
    "Additional useful parameters:\n",
    "- `inplace` -> whether to modify the original DataFrame (`True`) or return a new one (`False`)\n",
    "- `na_position` -> where to place NaN values ('first' or 'last')\n",
    "- `ignore_index` -> whether to reset the index after sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "491b7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2 col3\n",
      "0     1   444  abc\n",
      "1     2   555  def\n",
      "2     3   666  ghi\n",
      "3     4   777  xyz\n"
     ]
    }
   ],
   "source": [
    "# SORTING\n",
    "print(df.sort_values(by='col2', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08900a",
   "metadata": {},
   "source": [
    "### K(c). Custom Methods\n",
    "We can also create custom functions or methods to apply them to a dataframe. The `DataFrame.apply()` method takes a function or a method as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "778e0043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2 col3  col1*2\n",
      "0     1   444  abc       2\n",
      "1     2   555  def       4\n",
      "2     3   666  ghi       6\n",
      "3     4   777  xyz       8\n",
      "\n",
      "col3 has strings whose lengths are-\n",
      "0    3\n",
      "1    3\n",
      "2    3\n",
      "3    3\n",
      "Name: col3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# custom function\n",
    "def multiply_with_2(x):\n",
    "\treturn x*2\n",
    "\n",
    "# applying a custom function\n",
    "df['col1*2'] = df['col1'].apply(multiply_with_2)\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# applying a custom method \n",
    "print('col3 has strings whose lengths are-')\n",
    "print(df['col3'].apply(len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed306e0c",
   "metadata": {},
   "source": [
    "### L. Grouping\n",
    "\n",
    "Grouping is a powerful data analysis technique that allows us to:\n",
    "- Split data into groups based on one or more criteria\n",
    "- Perform calculations or operations on each group separately\n",
    "- Combine the results back into a meaningful format\n",
    "\n",
    "The `describe()` method provides a comprehensive statistical summary that includes count, mean, std, min, max, and quartile values all at once.\n",
    "\n",
    "You can also access these statistics individually using:\n",
    "- `count()` method -> returns the number of non-null values in each group\n",
    "- `mean()` method -> calculates the average value for numeric columns in each group\n",
    "- `std()` method -> calculates the standard deviation (measure of spread) for numeric columns\n",
    "- `min()` method -> returns the minimum value in each group\n",
    "- `max()` method -> returns the maximum value in each group\n",
    "\n",
    "The `transpose()` method flips rows and columns for easier viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4bb1c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Company   Person  Sales\n",
      "0     GOOGLE      Sam    200\n",
      "1       META  Charlie    120\n",
      "2     NVIDIA      Amy    340\n",
      "3     OPENAI  Vanessa    124\n",
      "4  MICROSOFT     Carl    243\n",
      "5      APPLE    Sarah    350\n",
      "\n",
      "\n",
      "Company      APPLE  GOOGLE   META  MICROSOFT  NVIDIA  OPENAI\n",
      "Sales count    1.0     1.0    1.0        1.0     1.0     1.0\n",
      "      mean   350.0   200.0  120.0      243.0   340.0   124.0\n",
      "      std      NaN     NaN    NaN        NaN     NaN     NaN\n",
      "      min    350.0   200.0  120.0      243.0   340.0   124.0\n",
      "      25%    350.0   200.0  120.0      243.0   340.0   124.0\n",
      "      50%    350.0   200.0  120.0      243.0   340.0   124.0\n",
      "      75%    350.0   200.0  120.0      243.0   340.0   124.0\n",
      "      max    350.0   200.0  120.0      243.0   340.0   124.0\n",
      "\n",
      "           Person  Sales\n",
      "Company                 \n",
      "APPLE           1      1\n",
      "GOOGLE          1      1\n",
      "META            1      1\n",
      "MICROSOFT       1      1\n",
      "NVIDIA          1      1\n",
      "OPENAI          1      1\n",
      "\n",
      "Sales  count      1.0\n",
      "       mean     340.0\n",
      "       std        NaN\n",
      "       min      340.0\n",
      "       25%      340.0\n",
      "       50%      340.0\n",
      "       75%      340.0\n",
      "       max      340.0\n",
      "Name: NVIDIA, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# GROUPING\n",
    "\n",
    "## create a new df\n",
    "data = {\n",
    "            'Company':['GOOGLE', 'META', 'NVIDIA', 'OPENAI', 'MICROSOFT', 'APPLE'],\n",
    "            'Person':['Sam', 'Charlie', 'Amy', 'Vanessa', 'Carl', 'Sarah'],\n",
    "            'Sales':[200, 120, 340, 124, 243, 350]\n",
    "\t}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "## use groupby()\n",
    "comp_gp = df.groupby(\"Company\")\n",
    "print()\n",
    "\n",
    "## describe the transposed group\n",
    "print(comp_gp.describe().transpose())\n",
    "print()\n",
    "\n",
    "## example of using an individual statistic method\n",
    "### mean(), std(), min(), max()\n",
    "print(comp_gp.count())\n",
    "print()\n",
    "\n",
    "## extract a variable\n",
    "nvidia = comp_gp.describe().transpose()['NVIDIA']\n",
    "print(nvidia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccfc51",
   "metadata": {},
   "source": [
    "### M. Concatenation, Merge, and Join\n",
    "\n",
    "Pandas provides three main operations for combining DataFrames:\n",
    "\n",
    "1. **Concatenation** with `pd.concat()` method:\n",
    "   - Combines DataFrames by stacking them either vertically (axis=0) or horizontally (axis=1)\n",
    "   - Useful when DataFrames have similar structure but different indices\n",
    "   - Preserves all data from input DataFrames\n",
    "\n",
    "2. **Merge** with `pd.merge()` method:\n",
    "   - Combines DataFrames based on common columns or indices, similar to SQL joins\n",
    "   - Requires at least one common column between DataFrames\n",
    "   - Supports different join types: inner, outer, left, right\n",
    "   - Useful for relating data from different sources based on common keys\n",
    "\n",
    "3. **Join** with `DataFrame.join()` method:\n",
    "   - Combines DataFrames based on their indices\n",
    "   - Simpler alternative to merge when combining on index\n",
    "   - By default performs a left join, but supports other join types (inner, outer)\n",
    "   - Particularly useful when DataFrames share an index but have different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22554d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    A    B    C    A    B    C\n",
      "0   A0   B0   C0  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "1   A1   B1   C1  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2   A2   B2   C2  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "3  NaN  NaN  NaN   A3   B3   C3  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN   A4   B4   C4  NaN  NaN  NaN\n",
      "5  NaN  NaN  NaN   A5   B5   C5  NaN  NaN  NaN\n",
      "6  NaN  NaN  NaN  NaN  NaN  NaN   A6   B6   C6\n",
      "7  NaN  NaN  NaN  NaN  NaN  NaN   A7   B7   C7\n",
      "8  NaN  NaN  NaN  NaN  NaN  NaN   A8   B8   C8\n"
     ]
    }
   ],
   "source": [
    "# CONCATENATION\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "\t{\n",
    "\t'A':'A0 A1 A2'.split(),\n",
    "\t'B':'B0 B1 B2'.split(),\n",
    "\t'C':'C0 C1 C2'.split()\n",
    "\t}, index=[0, 1, 2])\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "\t{\n",
    "\t'A':'A3 A4 A5'.split(),\n",
    "\t'B':'B3 B4 B5'.split(),\n",
    "\t'C':'C3 C4 C5'.split()\n",
    "\t}, index=[3, 4, 5])\n",
    "\n",
    "df3 = pd.DataFrame(\n",
    "\t{\n",
    "\t'A':'A6 A7 A8'.split(),\n",
    "\t'B':'B6 B7 B8'.split(),\n",
    "\t'C':'C6 C7 C8'.split()\n",
    "\t}, index=[6, 7, 8])\n",
    "\n",
    "print(pd.concat([df1, df2, df3], axis=1))  # concatenates horizontally # index matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5db11f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C\n",
      "0  A0  B0  C0\n",
      "1  A1  B1  C1\n",
      "2  A2  B2  C2\n",
      "\n",
      "    B   C   D   E\n",
      "0  B0  C0  D0  E0\n",
      "1  B1  C1  D1  E1\n",
      "2  B2  C2  D2  E2\n",
      "\n",
      "    A B_x   C B_y   D   E\n",
      "0  A0  B0  C0  B0  D0  E0\n",
      "1  A1  B1  C1  B1  D1  E1\n",
      "2  A2  B2  C2  B2  D2  E2\n",
      "\n",
      "    A B_x   C B_y   D   E\n",
      "0  A0  B0  C0  B0  D0  E0\n",
      "1  A1  B1  C1  B1  D1  E1\n",
      "2  A2  B2  C2  B2  D2  E2\n",
      "\n",
      "    A   B   C   D   E\n",
      "0  A0  B0  C0  D0  E0\n",
      "1  A1  B1  C1  D1  E1\n",
      "2  A2  B2  C2  D2  E2\n",
      "\n",
      "    A   B   C   D   E\n",
      "0  A0  B0  C0  D0  E0\n",
      "1  A1  B1  C1  D1  E1\n",
      "2  A2  B2  C2  D2  E2\n",
      "\n",
      "    A   B   C   D   E\n",
      "0  A0  B0  C0  D0  E0\n",
      "1  A1  B1  C1  D1  E1\n",
      "2  A2  B2  C2  D2  E2\n"
     ]
    }
   ],
   "source": [
    "# MERGE\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "\t{\n",
    "\t'A':'A0 A1 A2'.split(),\n",
    "\t'B':'B0 B1 B2'.split(),\n",
    "\t'C':'C0 C1 C2'.split()\n",
    "\t}, index=[0, 1, 2])\n",
    "print(df1)\n",
    "print()\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "\t{\n",
    "    'B':'B0 B1 B2'.split(),\n",
    "\t'C':'C0 C1 C2'.split(),\n",
    "\t'D':'D0 D1 D2'.split(),\n",
    "\t'E':'E0 E1 E2'.split()\n",
    "\t}, index=[0, 1, 2])\n",
    "print(df2)\n",
    "print()\n",
    "\n",
    "print(pd.merge(df1, df2, on='C'))\n",
    "print()\n",
    "print(pd.merge(df1, df2, how='inner', on=['C']))\n",
    "print()\n",
    "print(pd.merge(df1, df2, how='outer', on=['B', 'C']))\n",
    "print()\n",
    "print(pd.merge(df1, df2, how='right', on=['B', 'C']))\n",
    "print()\n",
    "print(pd.merge(df1, df2, how='left', on=['B', 'C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1ba0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B    C    D\n",
      "K0  A0  B0   C0   D0\n",
      "K1  A1  B1  NaN  NaN\n",
      "K2  A2  B2   C2   D2\n"
     ]
    }
   ],
   "source": [
    "# JOIN\n",
    "\n",
    "left = pd.DataFrame(\n",
    "\t{\n",
    "\t'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2']\n",
    "    }, index=['K0', 'K1', 'K2'])\n",
    "\n",
    "right = pd.DataFrame(\n",
    "\t{\n",
    "\t'C': ['C0', 'C2', 'C3'],\n",
    "    'D': ['D0', 'D2', 'D3']\n",
    "    }, index=['K0', 'K2', 'K3'])\n",
    "\n",
    "print(left.join(right)) # how=inner gives no nan rows # outer gives all nans rows\n",
    "# no how parameter gives no nan rows in left, right rows are adjusted to left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d745a6b",
   "metadata": {},
   "source": [
    "## Pivot Table\n",
    "A pivot table is a data summarization tool that can:\n",
    "- Reorganize and summarize selected columns and rows of data\n",
    "- Transform long-format data into a wider, more readable format\n",
    "- Create cross-tabulations of data\n",
    "- Aggregate data using various functions (sum, mean, count, etc.)\n",
    "\n",
    "The `DataFrame.pivot_table()` method creates a pivot table from a dataframe. Keys parameters are as follows.\n",
    "- `values` parameter -> column(s) to aggregate\n",
    "- `index` parameter -> column(s) to group by on rows\n",
    "- `columns` parameter -> column(s) to group by on columns\n",
    "- `aggfunc` parameter -> aggregation function(s) to use (default='mean')\n",
    "  - Common options: 'sum', 'mean', 'count', 'min', 'max'\n",
    "  - We can pass multiple functions as a list: ['sum', 'mean']\n",
    "- `fill_value` parameter -> value to replace missing data\n",
    "- `margins` parameter -> add row/column totals (default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21cfcfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Product Region  Sales  Units\n",
      "0  2024-01-01       A  North    100     10\n",
      "1  2024-01-01       B  South    200     20\n",
      "2  2024-01-02       A  North    150     15\n",
      "3  2024-01-02       B  South    250     25\n",
      "\n",
      "Region   North  South\n",
      "Product              \n",
      "A        125.0    NaN\n",
      "B          NaN  225.0\n",
      "\n",
      "         Sales             Units            \n",
      "Region   North  South  All North South   All\n",
      "Product                                     \n",
      "A        250.0    NaN  250  12.5   NaN  12.5\n",
      "B          NaN  450.0  450   NaN  22.5  22.5\n",
      "All      250.0  450.0  700  12.5  22.5  17.5\n"
     ]
    }
   ],
   "source": [
    "# creating a dataframe\n",
    "data = {\n",
    "    'Date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02'],\n",
    "    'Product': ['A', 'B', 'A', 'B'],\n",
    "    'Region': ['North', 'South', 'North', 'South'],\n",
    "    'Sales': [100, 200, 150, 250],\n",
    "    'Units': [10, 20, 15, 25]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# simple pivot table\n",
    "print(pd.pivot_table(df, \n",
    "                    values='Sales',\n",
    "                    index='Product',\n",
    "                    columns='Region'))\n",
    "print()\n",
    "\n",
    "# multiple aggregations\n",
    "print(pd.pivot_table(df,\n",
    "                    values=['Sales', 'Units'],\n",
    "                    index='Product',\n",
    "                    columns='Region',\n",
    "                    aggfunc={'Sales': 'sum', 'Units': 'mean'},\n",
    "                    margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f431a",
   "metadata": {},
   "source": [
    "## Reading and Writing Files\n",
    "We can read data from a CSV or an Excel file. Likewise, we can output our data to such formats.\n",
    "\n",
    "For a CSV format:\n",
    "- `pd.read_csv()` method -> reads CSV files into a dataframe\n",
    "- `pd.to_csv()` method -> writes dataframe to CSV\n",
    "\n",
    "For an Excel format:\n",
    "- `pd.read_excel()` method -> reads Excel files into a dataframe\n",
    "- `pd.to_excel()` method -> writes dataframe to Excel\n",
    "\n",
    "We can even read data from HTML using the `read_html()` method. It reads tables from HTML into list of dataframes. For this, we need to import the `lxml` and `html5lib` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dba7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lxml # uncomment this line to install\n",
    "# %pip install html5lib # uncomment this line to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc4a33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0c9092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rank                             Name     Industry      Revenue  \\\n",
      "  Rank                             Name     Industry USD millions   \n",
      "0    1                          Walmart       Retail     $648,125   \n",
      "1    2                           Amazon       Retail     $574,785   \n",
      "2    3  State Grid Corporation of China  Electricity     $545,948   \n",
      "3    4                     Saudi Aramco  Oil and gas     $494,890   \n",
      "4    5  China Petrochemical Corporation  Oil and gas     $429,700   \n",
      "\n",
      "        Profit Employees Headquarters[note 1] State-owned Ref.  \n",
      "  USD millions Employees Headquarters[note 1] State-owned Ref.  \n",
      "0      $15,511   2100000        United States         NaN  [1]  \n",
      "1      $30,425   1525000        United States         NaN  [4]  \n",
      "2       $9,204   1361423                China         NaN  [5]  \n",
      "3     $129,699     73311         Saudi Arabia         NaN  [6]  \n",
      "4       $9,393    513434                China         NaN  [7]  \n"
     ]
    }
   ],
   "source": [
    "# df1 = pd.read_csv('file.csv') # read csv file\n",
    "# df1.to_csv('example1', index=False) # write csv file\n",
    "\n",
    "# df2 = pd.read_excel('file.xlsx', sheet_name='Sheet1') # read excel file\n",
    "# df2.to_excel('Excel_Sample.xlsx', sheet_name='Sheet1') # write excel file\n",
    "\n",
    "tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_largest_companies_by_revenue') # read html\n",
    "df3 = tables[0]\n",
    "print(df3.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcc_machine_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
